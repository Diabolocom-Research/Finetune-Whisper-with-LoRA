This repository serves as a centralized collection of resources—tutorials, and other materials—sourced from the Diabolocom Research Team’s blog. The goal is to make it easy to find and leverage materials published at [Diabolocom Research](https://www.diabolocom.com/research/).

Below is a table of all available blog posts, along with their URLs and corresponding GitHub links (if available):

| Name | URL | GitHub Link |
| --- | --- | --- |
| EuroBERT: A Refreshed Encoder to Tackle Business Problems | https://www.diabolocom.com/research/eurobert-refreshed-encoder-to-tackle-business-problems/ | https://github.com/Nicolas-BZRD/EuroBERT |
| Applying Knowledge Distillation to LLMs with Different Vocabularies: the ULD Loss | https://www.diabolocom.com/research/applying-knowledge-distillation-llms-different-vocabularies-the-uld-loss/ | https://github.com/Diabolocom-Research/ULD-Loss |
| The Great Drop: ASR Performance in Conversational Settings! | https://www.diabolocom.com/research/the-great-drop-asr-performance-in-conversational-settings/ | https://github.com/Diabolocom-Research/ConversationalDataset |
| Unveiling the Potential of Synthetic Text Data: Evaluating LLM-Generated Benchmarks for NLP Tasks | https://www.diabolocom.com/research/synthetic-text-data-evaluating-llm-generated-benchmarks-nlp-tasks/ | https://github.com/Diabolocom-Research/SG4NLP |
| A Phonecall dataset for ASR Benchmarking Adapted To Conversational Settings | https://www.diabolocom.com/research/phonecall-d

Thought for 50 seconds

This repository serves as a centralized collection of resources—tutorials, and other materials—sourced from the Diabolocom Research Team’s blog. The goal is to make it easy to find and leverage materials published at [Diabolocom Research](https://www.diabolocom.com/research/).

Below is a table of all available blog posts, along with their URLs and corresponding GitHub links (if available):

| Name                                                                                                        | URL                                                                                                                                                | GitHub Link                                                                                                    |
|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| **EuroBERT: A Refreshed Encoder to Tackle Business Problems**                                               | [https://www.diabolocom.com/research/eurobert-refreshed-encoder-to-tackle-business-problems/](https://www.diabolocom.com/research/eurobert-refreshed-encoder-to-tackle-business-problems/) ([diabolocom.com](https://www.diabolocom.com/research/eurobert-refreshed-encoder-to-tackle-business-problems/)) | [https://github.com/Nicolas-BZRD/EuroBERT](https://github.com/Nicolas-BZRD/EuroBERT) ([github.com](https://github.com/Nicolas-BZRD/EuroBERT))                  |
| **Applying Knowledge Distillation to LLMs with Different Vocabularies: the ULD Loss**                       | [https://www.diabolocom.com/research/applying-knowledge-distillation-llms-different-vocabularies-the-uld-loss/](https://www.diabolocom.com/research/applying-knowledge-distillation-llms-different-vocabularies-the-uld-loss/) ([diabolocom.com](https://www.diabolocom.com/research/applying-knowledge-distillation-llms-different-vocabularies-the-uld-loss/)) | [https://github.com/Diabolocom-Research/ULD-Loss](https://github.com/Diabolocom-Research/ULD-Loss) ([github.com](https://github.com/Diabolocom-Research/ULD-Loss))        |
| **The Great Drop: ASR Performance in Conversational Settings!**                                             | [https://www.diabolocom.com/research/the-great-drop-asr-performance-in-conversational-settings/](https://www.diabolocom.com/research/the-great-drop-asr-performance-in-conversational-settings/) ([diabolocom.com](https://www.diabolocom.com/research/the-great-drop-asr-performance-in-conversational-settings/))   | [https://github.com/Diabolocom-Research/ConversationalDataset](https://github.com/Diabolocom-Research/ConversationalDataset) ([github.com](https://github.com/Diabolocom-Research/ConversationalDataset)) |
| **Unveiling the Potential of Synthetic Text Data: Evaluating LLM-Generated Benchmarks for NLP Tasks**     | [https://www.diabolocom.com/research/synthetic-text-data-evaluating-llm-generated-benchmarks-nlp-tasks/](https://www.diabolocom.com/research/synthetic-text-data-evaluating-llm-generated-benchmarks-nlp-tasks/) ([diabolocom.com](https://www.diabolocom.com/research/synthetic-text-data-evaluating-llm-generated-benchmarks-nlp-tasks/)) | [https://github.com/Diabolocom-Research/SG4NLP](https://github.com/Diabolocom-Research/SG4NLP) ([github.com](https://github.com/Diabolocom-Research/SG4NLP))          |
| **A Phonecall Dataset for ASR Benchmarking Adapted To Conversational Settings**                            | [https://www.diabolocom.com/research/phonecall-dataset-for-asr-benchmarking-adapted-to-conversational-settings/](https://www.diabolocom.com/research/phonecall-dataset-for-asr-benchmarking-adapted-to-conversational-settings/) ([diabolocom.com](https://www.diabolocom.com/research/phonecall-dataset-for-asr-benchmarking-adapted-to-conversational-settings/)) | [https://github.com/Diabolocom-Research/ConversationalDataset](https://github.com/Diabolocom-Research/ConversationalDataset) ([github.com](https://github.com/Diabolocom-Research/ConversationalDataset)) |

---

## License

This repository is distributed under the MIT License.  
All original blog posts remain © Diabolocom Research Team. This repository only hosts derivative metadata and, where permitted, local copies of publicly licensed resources.